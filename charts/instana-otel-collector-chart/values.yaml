# IDOT Chart Values Configuration
# 
# This file configures the Instana Distributed OpenTelemetry (IDOT) collectors for Kubernetes monitoring.
# 
# It defines two collectors:
# - daemonset: Runs on every node to collect host-level metrics, kubelet stats, and logs
# - statefulset: Runs as a single instance to collect cluster-level metrics and events
#
# The configuration is expressed in OpenTelemetry Collector syntax.
#
# Available parameters:
#
# clusterName: "cluster.local"                  # Name for the Kubernetes cluster
# clusterShortName: "cluster.local"             # Short name of the cluster
# clusterFullName: "cluster.local"              # Full name of the cluster
# clusterVersion: "v1.33.3"                     # Version of the cluster
# clusterDistribution: "kubernetes"             # Name of the cluster distribution
# clusterManagedBy: "provider"                  # Name of the organization managing the cluster
#
# namespaceName: "default"                      # Namespace of the Kubernetes cluster
#
# serviceInstanceId: "otelk8sid"                # Service instance ID for tracing
# serviceName: "otelk8s"                        # Service name for use in tracing
#
# INSTANA_PLUGIN: "k8s"                         # Mandatory constant for use internally by Instana
#
# instanaEndpoint: "localhost:4317"             # The Instana backend endpoint or Instana Agent endpoint
# instanaKey: "instanalocal"                    # The Instana agent key to use
#
# OpenShift-specific configuration
#
# openshift:
#   # Enable OpenShift mode explicitly (overrides auto-detection)
#   enabled: false 
#   # Enable automatic OpenShift detection (default: true)
#   autoDetect: true
#   # DaemonSet-specific OpenShift configuration
#   daemonset:
#     # When true, creates a privileged SCC
#     usePrivilegedServiceAccount: true
#
# | Preset               | DaemonSet | StatefulSet | Description                           |
# | -------------------- | --------- | ----------- | ------------------------------------- |
# | kubernetesAttributes | Yes       | Yes         | Enrich telemetry with K8s metadata    |
# | kubeletMetrics       | Yes       | No          | Collect node and pod metrics          |
# | hostMetrics          | Yes       | No          | Collect host-level CPU/mem/disk       |
# | logsCollection       | No        | No          | Collect application/container logs    |
# | kubernetesEvents     | No        | Yes         | Collect Kubernetes event stream       |
# | clusterMetrics       | No        | Yes         | Collect cluster-wide resource metrics |

# ------------------------------------------------------------------------------
# DaemonSet — runs on every node to collect node/pod metrics & logs
# ------------------------------------------------------------------------------
daemonset:
  mode: daemonset
  image:
    repository: icr.io/instana/idot
    tag: latest
  presets:
    # Enables the k8sattributesprocessor and adds it to the traces, metrics, and logs pipelines
    kubernetesAttributes:
      enabled: true
      extractAllPodLabels: true
      extractAllPodAnnotations: true
    # Enables the kubeletstatsreceiver and adds it to the metrics pipelines
    kubeletMetrics:
      enabled: true
    # Enables the hostmetricsreceiver and adds it to the metrics pipelines
    hostMetrics:
      enabled: true
    # Enables log collection by the collector
    logsCollection:
      enabled: false
      includeCollectorLogs: false
      maxRecombineLogSize: 102400
  extraEnvsFrom:
    - configMapRef:
        name: idot-env-config # Loads environment variables (Instana keys, endpoint, etc.)
  clusterRole: # Required to enrich telemetry with node/cluster metadata
    create: true
    rules:
      - apiGroups: [""]
        resources: ['nodes', 'nodes/stats', 'nodes/proxy', 'endpoints']
        verbs: ["get", "list", "watch"] # Needed for k8s.node.uid enrichment
  config:
    processors:
      memory_limiter: # Prevents OTel collector from exceeding memory limits
        check_interval: 1s
        limit_percentage: 50
        spike_limit_percentage: 10
      groupbyattrs/grouping: # Groups telemetry by cluster UID before batching/export
        keys: [k8s.cluster.uid]
      k8sattributes: # Adds Kubernetes metadata (namespace, pod, node, etc.)
        auth_type: 'serviceAccount'
        extract:
          metadata: # Extracted from the pod
            # Defaults
            - k8s.namespace.name   
            - k8s.deployment.name
            - k8s.statefulset.name
            - k8s.daemonset.name
            - k8s.cronjob.name
            - k8s.job.name
            - k8s.node.name
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.pod.start_time
            # Custom
            - k8s.node.uid   # Requires get, watch, and list permissions for nodes resources
            - k8s.cluster.uid
            - container.id
        pod_association: # How to associate the data to a pod (order matters)
          - sources: # First try pod IP
              - from: resource_attribute
                name: k8s.pod.ip
          - sources: # Fallback: pod UID
              - from: resource_attribute
                name: k8s.pod.uid
          - sources: # Fallback: node name
              - from: resource_attribute
                name: k8s.node.name
          - sources: # Last resort: use connection to get pod IP
              - from: connection
      transform/severity_parse: # Normalizes log severity from log body strings
        log_statements:
          - context: log
            statements:
              - set(severity_text, "Info")  where IsMatch(body.string, ".*INFO.*")
              - set(severity_text, "Warn")  where IsMatch(body.string, ".*WARN.*")
              - set(severity_text, "Error") where IsMatch(body.string, ".*ERROR.*")
              - set(severity_text, "Fatal") where IsMatch(body.string, ".*FATAL.*")
      resourcedetection/env: # Detects cluster info (name, region) from environment variables
        detectors:
          - env
      transform/resource_adjustments:
        error_mode: ignore
        metric_statements:
          - context: resource
            statements:
              # Set INSTANA_PLUGIN to "k8s" if k8s.cluster.uid exists
              - set(resource.attributes["INSTANA_PLUGIN"], "k8s") where resource.attributes["k8s.cluster.uid"] != nil and resource.attributes["entity.type"] != "otel-collector"
              # For otel-collector entity, set service.name = k8s.cluster.name
              - set(resource.attributes["service.name"], resource.attributes["k8s.cluster.name"]) where resource.attributes["entity.type"] == "otel-collector"
        trace_statements:
          - context: resource
            statements:
              - set(resource.attributes["INSTANA_PLUGIN"], "k8s") where resource.attributes["k8s.cluster.uid"] != nil and resource.attributes["entity.type"] != "otel-collector"
              - set(resource.attributes["service.name"], resource.attributes["k8s.cluster.name"]) where resource.attributes["entity.type"] == "otel-collector"
        log_statements:
          - context: resource
            statements:
              - set(resource.attributes["INSTANA_PLUGIN"], "k8s") where resource.attributes["k8s.cluster.uid"] != nil and resource.attributes["entity.type"] != "otel-collector"
              - set(resource.attributes["service.name"], resource.attributes["k8s.cluster.name"]) where resource.attributes["entity.type"] == "otel-collector"
    receivers:
      hostmetrics:
        collection_interval: 30s
      kubeletstats:
        insecure_skip_verify: true
        node: '${env:K8S_NODE_NAME}'
        metrics:
          k8s.container.cpu.node.utilization:
            enabled: true
          k8s.pod.cpu.node.utilization:
            enabled: true
          k8s.container.memory.node.utilization:
            enabled: true
          k8s.pod.memory.node.utilization:
            enabled: true
          container.uptime:
            enabled: true
          container.memory.available:
            enabled: true
        extra_metadata_labels:
          - container.id
      otlp: # Enables OTLP ingestion (both gRPC and HTTP) for metrics, logs, traces
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:4317
          http:
            endpoint: ${env:MY_POD_IP}:4318
    exporters:
      otlp/instana: # Sends telemetry to Instana backend
        endpoint: '${env:INSTANA_ENDPOINT}'
        tls:
          insecure: false # Set false in production for TLS enforcement
        headers:
          x-instana-key: '${env:INSTANA_KEY}'
      debug: {} # Debugging exporter — writes telemetry to stdout
    service:
      pipelines:
        metrics:
          receivers:
          - otlp
          - hostmetrics
          - kubeletstats
          exporters:
          # - debug
          - otlp/instana
          processors:
          - resourcedetection/env # Adds environment resource attributes first
          - k8sattributes         # Enriches telemetry with Kubernetes metadata
          - memory_limiter        # Protects collector from memory spikes 
          - transform/resource_adjustments
          - batch                 # Batches metrics for efficient export
        logs:
          exporters:
          # - debug
          - otlp/instana
        traces:
          receivers:
          - otlp
          exporters:
          # - debug
          - otlp/instana
          processors:
          - resourcedetection/env # Adds environment resource attributes first
          - k8sattributes         # Enriches telemetry with Kubernetes metadata
          - memory_limiter        # Protects collector from memory spikes
          - transform/resource_adjustments
          - batch                 # Batches traces for efficient export
      # Collector's own telemetry configuration (self-monitoring)
      telemetry:
        # Metrics telemetry configuration
        metrics:
          readers:
            - periodic:
                exporter:
                  otlp:
                    protocol: http/protobuf
                    endpoint: ${env:MY_POD_IP}:4318
        # Log telemetry configuration
        logs:
          level: INFO
          processors:
            - batch:
                exporter:
                  otlp:
                    protocol: http/protobuf
                    endpoint: ${env:MY_POD_IP}:4318
        # Resource attributes for identifying the collector itself
        resource:
          service.name: ${env:INSTANA_OTEL_SERVICE_NAME:-otel-collector}
          service.version: ${env:INSTANA_OTEL_SERVICE_VERSION}
          service.instance.id: ${env:HOSTNAME}
          entity.type: ${env:INSTANA_OTEL_ENTITY_TYPE:-otel-collector}
  tolerations:
    - key: node-role.kubernetes.io/master
      operator: Exists
      effect: NoSchedule
    - key: node-role.kubernetes.io/control-plane
      operator: Exists
      effect: NoSchedule
    - key: CriticalAddonsOnly
      operator: Exists
      effect: NoExecute

# ------------------------------------------------------------------------------
# StatefulSet — runs a small set of pods for cluster-wide data (events, metrics)
# ------------------------------------------------------------------------------
statefulset:
  mode: statefulset
  replicaCount: 1
  image:
    repository: icr.io/instana/idot
    tag: latest
  presets:
    # Enables the k8sattributesprocessor and adds it to the traces, metrics, and logs pipelines
    kubernetesAttributes:
      enabled: true
      extractAllPodLabels: true
      extractAllPodAnnotations: true
    # Enables the kubeletstatsreceiver and adds it to the metrics pipelines
    kubeletMetrics:
      enabled: false
    # Enables the filelogreceiver and adds it to the logs pipelines
    logsCollection:
      enabled: false
    # Enables the hostmetricsreceiver and adds it to the metrics pipelines
    hostMetrics:
      enabled: false
    # Enables the kuberneteseventsreceiver and adds it to the logs pipelines
    kubernetesEvents:
      enabled: true
    # Enables the cluster metrics receiver
    clusterMetrics:
      enabled: true
  extraEnvsFrom:
    - configMapRef:
        name: idot-env-config # Loads environment variables (Instana keys, endpoint, etc.)
  config:
    processors:
      memory_limiter: # Prevents OTel collector from exceeding memory limits
        check_interval: 1s
        limit_percentage: 50
        spike_limit_percentage: 10
      groupbyattrs/grouping: # Groups telemetry by cluster UID before batching/export
        keys: [k8s.cluster.uid]
      k8sattributes: # Adds Kubernetes metadata (namespace, pod, node, etc.)
        auth_type: 'serviceAccount'
        extract:
          metadata: # Extracted from the pod
            # Defaults
            - k8s.namespace.name   
            - k8s.deployment.name
            - k8s.statefulset.name
            - k8s.daemonset.name
            - k8s.cronjob.name
            - k8s.job.name
            - k8s.node.name
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.pod.start_time
            # Custom
            - k8s.node.uid   # Requires get, watch, and list permissions for nodes resources
            - k8s.cluster.uid
        pod_association: # How to associate the data to a pod (order matters)
          - sources: # First try pod IP
              - from: resource_attribute
                name: k8s.pod.ip
          - sources: # Fallback: pod UID
              - from: resource_attribute
                name: k8s.pod.uid
          - sources: # Fallback: namespace name
              - from: resource_attribute
                name: k8s.namespace.name
          - sources: # Fallback: namespace UID
              - from: resource_attribute
                name: k8s.namespace.uid
          - sources: # Fallback: node name
              - from: resource_attribute
                name: k8s.node.name
          - sources: # Last resort: use connection to get pod IP
              - from: connection
      resourcedetection/env: # Detects cluster info (name, region) from environment variables
        detectors:
          - env
      transform/resource_adjustments:
        error_mode: ignore
        metric_statements:
          - context: resource
            statements:
              # Set INSTANA_PLUGIN to "k8s" if k8s.cluster.uid exists
              - set(resource.attributes["INSTANA_PLUGIN"], "k8s") where resource.attributes["k8s.cluster.uid"] != nil and resource.attributes["entity.type"] != "otel-collector"
              # For otel-collector entity, set service.name = k8s.cluster.name
              - set(resource.attributes["service.name"], resource.attributes["k8s.cluster.name"]) where resource.attributes["entity.type"] == "otel-collector"
        trace_statements:
          - context: resource
            statements:
              - set(resource.attributes["INSTANA_PLUGIN"], "k8s") where resource.attributes["k8s.cluster.uid"] != nil and resource.attributes["entity.type"] != "otel-collector"
              - set(resource.attributes["service.name"], resource.attributes["k8s.cluster.name"]) where resource.attributes["entity.type"] == "otel-collector"
        log_statements:
          - context: resource
            statements:
              - set(resource.attributes["INSTANA_PLUGIN"], "k8s") where resource.attributes["k8s.cluster.uid"] != nil and resource.attributes["entity.type"] != "otel-collector"
              - set(resource.attributes["service.name"], resource.attributes["k8s.cluster.name"]) where resource.attributes["entity.type"] == "otel-collector"
    exporters:
      otlp/instana: # Sends telemetry to Instana backend
        endpoint: '${env:INSTANA_ENDPOINT}'
        tls:
          insecure: false # Set false in production for TLS enforcement
        headers:
          x-instana-key: '${env:INSTANA_KEY}'
      debug: {} # Debugging exporter — writes telemetry to stdout
    service:
      pipelines:
        metrics:
          receivers:
          - otlp
          - k8s_cluster
          exporters:
          # - debug
          - otlp/instana
          processors:
          - resourcedetection/env # Adds environment resource attributes first
          - k8sattributes         # Enriches telemetry with Kubernetes metadata
          - memory_limiter        # Protects collector from memory spikes 
          - transform/resource_adjustments
          - batch                 # Batches metrics for efficient export
        logs:
          exporters:
          # - debug
          - otlp/instana
        traces:
          receivers:
          - otlp
          exporters:
          # - debug
          - otlp/instana
          processors:
          - resourcedetection/env # Adds environment resource attributes first
          - k8sattributes         # Enriches telemetry with Kubernetes metadata
          - memory_limiter        # Protects collector from memory spikes
          - transform/resource_adjustments
          - batch                 # Batches traces for efficient export
      # Collector's own telemetry configuration (self-monitoring)
      telemetry:
        # Metrics telemetry configuration
        metrics:
          readers:
            - periodic:
                exporter:
                  otlp:
                    protocol: http/protobuf
                    endpoint: ${env:MY_POD_IP}:4318
        # Log telemetry configuration
        logs:
          level: INFO
          processors:
            - batch:
                exporter:
                  otlp:
                    protocol: http/protobuf
                    endpoint: ${env:MY_POD_IP}:4318
        # Resource attributes for identifying the collector itself
        resource:
          service.name: ${env:INSTANA_OTEL_SERVICE_NAME:-otel-collector}
          service.version: ${env:INSTANA_OTEL_SERVICE_VERSION}
          service.instance.id: ${env:HOSTNAME}
          entity.type: ${env:INSTANA_OTEL_ENTITY_TYPE:-otel-collector}
